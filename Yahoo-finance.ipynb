{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c2bf3f-48d0-4e8a-ad3f-752a52d342de",
   "metadata": {},
   "source": [
    "# Imports and Configrations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b142ee-c7e4-4f38-ae56-90e4ffc9b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935823c-f9b5-4f32-9aa5-88ec55264555",
   "metadata": {},
   "source": [
    "# URLs Used in Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96e10c31-30d7-4a04-aaf5-4ff481378163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for URLs and selectors\n",
    "YAHOO_FINANCE_URL = \"https://finance.yahoo.com/\"\n",
    "TRENDING_STOCKS_URL = \"https://finance.yahoo.com/trending-tickers\"\n",
    "STOCK_DATA_XPATH = \"//table[contains(@class, 'W(100%)')]//tbody//tr\"\n",
    "OUTPUT_EXCEL_FILE = \"yahoo_stocks_data.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092338e-6a90-48b1-b147-2c37fff70551",
   "metadata": {},
   "source": [
    "# WebDriver Initialization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a40106-c28c-42f3-a23e-4c3ac0e61293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_webdriver(headless: bool = True) -> webdriver.Chrome:\n",
    "    # Initializes and returns a Chrome WebDriver instance.\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    options.add_argument(\"--window-size=1920,1080\") # Set a default window size for headless mode\n",
    "\n",
    "    try:\n",
    "        # Assuming chromedriver is in PATH or provide the path explicitly\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        print(\"WebDriver initialized successfully.\")\n",
    "        return driver\n",
    "    except WebDriverException as e:\n",
    "        logging.error(f\"Error initializing WebDriver: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efc6a9-3693-4161-8a50-932eaa0bf997",
   "metadata": {},
   "source": [
    "# Navigation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce322783-756e-4133-9753-146b267ace5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_to_page(driver: webdriver.Chrome, url: str, wait_time: int = 10, page_title: str = \"\") -> bool:\n",
    "    # Navigates to a given URL and waits for the page to load.\n",
    "    try:\n",
    "        print(f\"Navigating to {url}\")\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, wait_time).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        if page_title:\n",
    "            WebDriverWait(driver, wait_time).until(EC.title_contains(page_title))\n",
    "        print(f\"Page '{driver.title}' loaded successfully.\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while loading page: {url}. Title: {driver.title}\")\n",
    "        return False\n",
    "    except WebDriverException as e:\n",
    "        print(f\"WebDriver error navigating to {url}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afedb96-b248-416b-b038-5504d6a7f680",
   "metadata": {},
   "source": [
    "# Data Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b19aec0-d401-4f6e-a819-303e93ecbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trending_stock_data(driver: webdriver.Chrome, xpath: str, max_retries: int = 3) -> list[list[str]]:\n",
    "    # Extracts trending stock data from a table using the specified XPath.\n",
    "    all_stock_data = []\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "            rows = driver.find_elements(By.XPATH, xpath)\n",
    "            if not rows:\n",
    "                logging.warning(f\"No rows found with XPath: {xpath} on attempt {attempt + 1}\")\n",
    "                time.sleep(2) # Wait before retrying\n",
    "                continue\n",
    "\n",
    "            for row in rows:\n",
    "                try:\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                    # Extract text from each cell, strip whitespace\n",
    "                    row_data = [cell.text.strip() for cell in cells]\n",
    "                    if row_data:\n",
    "                        all_stock_data.append(row_data)\n",
    "                except NoSuchElementException:\n",
    "                    logging.warning(\"Skipping a row due to missing cells.\")\n",
    "                    continue\n",
    "            logging.info(f\"Successfully extracted {len(all_stock_data)} stock entries.\")\n",
    "            break # Exit loop if data extracted\n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Timeout waiting for stock data table on attempt {attempt + 1}.\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An unexpected error occurred during data extraction on attempt {attempt + 1}: {e}\")\n",
    "            time.sleep(2)\n",
    "    return all_stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d57441-d230-4c54-b95f-9aa1dcdb34ef",
   "metadata": {},
   "source": [
    "# Data Cleaning and Conversion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "267267de-ebe6-45cf-8da8-d2b72e7aa4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert_data(raw_data: list[list[str]]) -> pd.DataFrame:\n",
    "    # Cleans and converts raw scraped stock data into a Pandas DataFrame.\n",
    "\n",
    "    # Define columns based on Yahoo Finance trending tickers table\n",
    "    # This might need adjustment if the actual scraped data columns vary\n",
    "    columns = [\n",
    "        \"Symbol\", \"Name\", \"Last Price (Intraday)\", \"Change\", \"% Change\",\n",
    "        \"Volume\", \"Avg Vol (3 month)\", \"Market Cap\", \"PE Ratio (TTM)\",\n",
    "         \"% Change (YTD)\", \"Graph\" # \"Graph\" column is usually an image/sparkline\n",
    "    ]\n",
    "\n",
    "    # Handle cases where rows might have fewer columns than expected\n",
    "    processed_data = []\n",
    "    for row in raw_data:\n",
    "        if len(row) == len(columns):\n",
    "            processed_data.append(row)\n",
    "        elif len(row) > len(columns):\n",
    "            # If more columns, truncate to expected number\n",
    "            processed_data.append(row[:len(columns)])\n",
    "            logging.warning(f\"Row truncated: {row}\")\n",
    "        else:\n",
    "            # If fewer columns, pad with None or empty string\n",
    "            padded_row = row + [''] * (len(columns) - len(row))\n",
    "            processed_data.append(padded_row)\n",
    "            logging.warning(f\"Row padded: {row}\")\n",
    "\n",
    "\n",
    "    stocks_df = pd.DataFrame(processed_data, columns=columns)\n",
    "\n",
    "    # Data type conversion and cleaning\n",
    "    # Remove characters like 'M', 'B', 'T', '%' and convert to numeric\n",
    "    def clean_numeric_string(s):\n",
    "        if pd.isna(s) or not isinstance(s, str):\n",
    "            return None\n",
    "        s = s.replace(',', '').strip()\n",
    "        if 'T' in s:\n",
    "            return float(s.replace('T', '')) * 1_000_000_000_000\n",
    "        elif 'B' in s:\n",
    "            return float(s.replace('B', '')) * 1_000_000_000\n",
    "        elif 'M' in s:\n",
    "            return float(s.replace('M', '')) * 1_000_000\n",
    "        elif '%' in s:\n",
    "            return float(s.replace('%', '')) / 100\n",
    "        try:\n",
    "            return float(s)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    # Apply cleaning to relevant columns\n",
    "    numeric_cols = [\n",
    "        \"Last Price (Intraday)\", \"Change\", \"% Change\", \"Volume\",\n",
    "        \"Avg Vol (3 month)\", \"Market Cap\", \"PE Ratio (TTM)\", \"% Change (YTD)\"\n",
    "    ]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in stocks_df.columns:\n",
    "            stocks_df[col] = stocks_df[col].apply(clean_numeric_string)\n",
    "        else:\n",
    "            logging.warning(f\"Column '{col}' not found in DataFrame for cleaning.\")\n",
    "\n",
    "    # Drop the 'Graph' column as it's not data\n",
    "    if \"Graph\" in stocks_df.columns:\n",
    "        stocks_df.drop(columns=[\"Graph\"], inplace=True)\n",
    "\n",
    "    logging.info(\"Data cleaning and conversion complete.\")\n",
    "    return stocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a125a-34ce-459e-8ef9-57192bc8b7ef",
   "metadata": {},
   "source": [
    "# Data Export Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44203a93-8808-46aa-b309-89b3731a5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dataframe_to_excel(df: pd.DataFrame, file_path: str):\n",
    "    # Exports a Pandas DataFrame to an Excel file.\n",
    "    try:\n",
    "        df.to_excel(file_path, index=False)\n",
    "        logging.info(f\"Data successfully exported to {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error exporting data to Excel: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc35525-8c5a-4c6f-9c81-4ed3bdbae327",
   "metadata": {},
   "source": [
    "# Main Execution Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d92227b-c2fe-4c71-b02a-3b960bb9f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebDriver initialized successfully.\n",
      "Navigating to https://finance.yahoo.com/trending-tickers\n",
      "Page 'Top Trending Stocks: US stocks with the highest interest today - Yahoo Finance' loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Timeout waiting for stock data table on attempt 1.\n",
      "ERROR:root:Timeout waiting for stock data table on attempt 2.\n",
      "ERROR:root:Timeout waiting for stock data table on attempt 3.\n",
      "WARNING:root:No stock data extracted. Skipping data processing and export.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution Flow ---\n",
    "if __name__ == \"__main__\":\n",
    "    driver = None\n",
    "    try:\n",
    "        logging.info(\"Starting Yahoo Finance Trending Stocks Scraper.\")\n",
    "        driver = initialize_webdriver(headless=True) # Run in headless mode\n",
    "\n",
    "        # Navigate to Trending Tickers page\n",
    "        if not navigate_to_page(driver, TRENDING_STOCKS_URL, page_title=\"Trending Stocks\"):\n",
    "            logging.error(\"Failed to load Trending Stocks page. Exiting.\")\n",
    "            exit()\n",
    "\n",
    "        # Extract data\n",
    "        raw_stocks_data = extract_trending_stock_data(driver, STOCK_DATA_XPATH)\n",
    "\n",
    "        if raw_stocks_data:\n",
    "            # Process data\n",
    "            stocks_df = clean_and_convert_data(raw_stocks_data)\n",
    "\n",
    "            # Display head of the processed DataFrame\n",
    "            logging.info(\"Preview of the processed DataFrame:\")\n",
    "            print(stocks_df.head().to_markdown(index=False)) # Use to_markdown for clean print in console\n",
    "\n",
    "            # Export to Excel\n",
    "            export_dataframe_to_excel(stocks_df, OUTPUT_EXCEL_FILE)\n",
    "        else:\n",
    "            logging.warning(\"No stock data extracted. Skipping data processing and export.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"An unhandled error occurred during the scraping process: {e}\")\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            logging.info(\"WebDriver closed.\")\n",
    "        logging.info(\"Scraping process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a06c6a-c3a0-4665-92ba-06a88935e4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
